**Lec 11**

![[Pasted image 20241119133043.png]]
다중 퍼셉트론 (Multi-layer Perceptron, MLP) 모델을 사용하여 이미지 분류를 수행하는 과정
	MLP는 입력층, 여러 개의 은닉층, 출력층으로 구성된 신경망 모델로, 주로 이미지나 텍스트 분류에 사용됨.

위 input image의 경우 28\*28 = 784개의 픽셀로 이루어져 있으며, MLP 모델에 입력하기 위해 1차원 벡터 형태로 펼쳐서 사용. => 입력 벡터 x의 차원 : 784

#### MLP 구조
- **은닉층**(Hidden Layers)은 여러 개의 노드로 구성되며, 각 노드가 서로 연결되어 있습니다.
- 입력층과 은닉층, 은닉층 간, 그리고 마지막 은닉층과 출력층 간에는 **가중치 행렬**(Weight Matrix)이 존재합니다. 각 가중치 행렬은 서로 다른 차원을 가지며, 모델이 학습해야 할 파라미터가 됩니다.
    - **첫 번째 은닉층** W_1​: 784×256 크기의 가중치 행렬
    - **두 번째 은닉층** W_2​: 256×128 크기의 가중치 행렬
    - **세 번째 은닉층** W_3​: 128×64 크기의 가중치 행렬
    - **네 번째 은닉층** W_4​: 64×10 크기의 가중치 행렬
- 이와 같이 각 층의 노드와 다음 층의 노드가 모두 연결되어 있어, MLP는 **완전 연결층**(Fully Connected Layer) 구조를 갖습니다.

#### 출력 벡터
- 마지막 출력 벡터 y의 차원은 10입니다. 이는 10개의 노드를 의미하며, 각 노드는 **0에서 9까지의 숫자 클래스** 중 하나에 해당합니다. 이 출력 벡터는 숫자가 특정 클래스에 속할 확률을 나타냅니다.
- 예를 들어, 이미지가 숫자 "7"을 나타내는 경우, "7"에 해당하는 노드가 높은 값을 갖고 나머지 노드는 낮은 값을 갖게 됩니다.

#### 총 파라미터 수
- MLP 모델이 학습해야 하는 파라미터의 총 개수는 각 가중치 행렬의 원소 수를 모두 더한 값입니다.
    - (784×256)+(256×128)+(128×64)+(64×10)=235,392
- 따라서, 이 MLP 모델의 총 파라미터 수는 **235,392개**입니다.
- 
이러한 구조를 통해, MLP는 입력 이미지를 여러 은닉층을 통해 처리하여 각 클래스에 대한 확률 값을 출력하게 됩니다.

---
![[Pasted image 20241119133923.png]]
위 이미지는 기존 다층 퍼셉트론(MLP) 구조가 **더 큰 이미지**와 **RGB 컬러 값을 가진 입력**에 대해 어떻게 변할 수 있는지를 보여준다.
input image의 개 사진은 224\*224\*3이다. (가로, 세로, RGB채널)
입력 벡터 x 차원은 224\*224\*3 = 150,528 (1차원 벡터)

#### MLP 구조
- 이미지가 더 커지고 RGB 채널을 포함하므로 입력 벡터의 차원이 커지게 됩니다. 따라서, 각 층의 가중치 행렬도 차원이 커지며, 모델의 파라미터 수가 증가하게 됩니다.
- 여전히 각 층은 완전 연결층으로 구성되어 있으며, 가중치 행렬의 차원이 다음과 같이 변경됩니다.
    - **첫 번째 은닉층** W_1: 150,528×256 크기의 가중치 행렬
    - **두 번째 은닉층** W_2​: 256×128 크기의 가중치 행렬
    - **세 번째 은닉층** W_3​: 128×64 크기의 가중치 행렬
    - **네 번째 은닉층** W_4​: 64×10 크기의 가중치 행렬
- 이와 같이 가중치 행렬이 커지기 때문에, 모델의 파라미터 수가 급격히 증가합니다.

#### 출력 벡터
- 출력층의 크기는 여전히 **10차원**으로, 숫자 "0"에서 "9"까지의 클래스 중 하나를 예측하는 구조입니다.

#### 총 파라미터 수
- 이미지 크기와 채널이 증가하면서 MLP 모델의 파라미터 수도 크게 늘어납니다.
    - (3×224×224×256)+(256×128)+(128×64)+(64×10)=38,576,7683
- 따라서, 이 MLP 모델의 총 파라미터 수는 **약 38.6백만 개**로, 이전의 흑백 이미지보다 훨씬 많은 파라미터를 필요로 합니다.

#### 추가적인 고려 사항
- **이미지 크기가 커지거나 색상 채널이 추가**되면, **MLP 구조에서 학습해야 할 파라미터 수가 기하급수적으로 증가**합니다. 이는 학습 속도와 메모리 사용량에 큰 부담을 주기 때문에, 일반적으로 CNN(Convolutional Neural Networks) 같은 모델을 사용하여 이미지 분류를 수행하는 것이 효율적입니다.

---
![[Pasted image 20241119135553.png]]
#### 완전 연결층
- MLP의 **완전 연결층**은 **이미지의 모든 픽셀을 한 번에 고려하여 학습하는 구조**입니다.
- 이는 각 픽셀과 다음 층의 모든 노드가 연결되어 있다는 뜻으로, 이미지의 모든 정보를 한꺼번에 처리하게 됩니다.

#### 많은 가중치 파라미터 요구
- MLP는 이미지의 모든 픽셀을 연결하므로, 가중치 파라미터의 수가 매우 많아집니다.
- 예를 들어, 28×28=784 픽셀을 가진 작은 이미지라도 많은 가중치가 필요하며, 이미지가 커질수록 파라미터 수는 기하급수적으로 증가합니다.
- 따라서, 계산 복잡성이 높아지고 모델이 매우 큰 메모리를 요구하게 되어 비효율적입니다.

#### 더 효율적인 이미지 처리 방법 필요성
- 슬라이드의 하단에 있는 질문, "Can we process images in a more efficient and effective way?"(우리는 이미지를 더 효율적이고 효과적으로 처리할 수 있을까?)는 MLP보다 더 적은 파라미터로 이미지를 효율적으로 처리할 수 있는 방법의 필요성을 시사합니다.
- 예를 들어, **합성곱 신경망(CNN)** 은 지역적 패턴을 학습하며, MLP와 달리 모든 픽셀을 한꺼번에 처리하지 않고 **작은 영역 단위로 학습**합니다. CNN은 MLP보다 훨씬 적은 가중치로도 이미지의 주요 특징을 효과적으로 학습할 수 있기 때문에 이미지 처리에 더 적합합니다.

따라서, MLP는 이미지의 모든 픽셀을 독립적으로 다루며 많은 가중치를 요구하는 비효율적인 구조인 반면, CNN과 같은 다른 모델들은 더 효율적이고 효과적으로 이미지를 처리할 수 있습니다.

---
![[Pasted image 20241119135737.png]]
![[Pasted image 20241119140013.png]]
#### 이미지의 공간적 구조
- 이미지는 단순히 임의의 벡터가 아닌, **공간적 구조**를 가지고 있습니다.
    - 예를 들어, 숫자 "7" 이미지의 일부가 다른 부분보다 더 중요한 정보일 수 있습니다.
    - 이는 이미지의 특정 영역이 다른 영역보다 더 중요한 정보를 담고 있음을 의미합니다.
- 이러한 **공간적 구조** 때문에, **이미지 처리에서는 각 픽셀의 위치 관계가 중요합니다.**

#### 이미지 변형에 대한 유사성 유지
- 이미지의 내용은 크기가 바뀌거나 회전, 위치 이동 등의 변형이 일어나도 **유사성**을 유지할 수 있습니다.
    - 왼쪽 상단의 숫자 "7" 이미지는 크기나 위치가 다르지만 여전히 같은 "7"으로 인식될 수 있습니다.
    - 오른쪽 하단의 강아지 이미지도 회전된 상태이지만, 본질적으로 동일한 강아지 사진입니다.
- 이는 이미지 처리 모델이 **크기, 회전, 위치** 변화에 대해 강건성을 가져야 함을 시사합니다.

#### 이미지의 계층적 특성
- 이미지는 단순한 선이나 모서리 같은 **저수준 특징**부터 시작해 점차 복잡한 **고수준 특징**으로 구성됩니다.
    - 예를 들어, 얼굴 이미지에서 선은 눈, 코, 입 같은 **형태**를 만들고, 이러한 형태가 모여 얼굴이라는 **패턴**을 형성합니다.
    - 이러한 **계층적 구조로 인해 이미지 분석 모델은 저수준의 특징을 먼저 학습하고, 이를 바탕으로 점차적으로 고수준 특징을 학습할 수 있습니다.**
##### 예시
- 왼쪽 예시에서는 얼굴 이미지를 작은 부분으로 나누어 **눈**을 나타내는 저수준 특징부터 **얼굴 전체**라는 고수준 특징까지 점진적으로 학습하는 과정을 보여줍니다.
- 오른쪽 강아지 이미지 예시에서도 강아지의 얼굴을 중심으로 점진적으로 확대하면서 중요한 특징을 포착해 나가는 과정을 묘사하고 있습니다.

##### 질문: 어떻게 위치, 회전, 크기 변화에 불변적인 특징을 추출할 수 있을까?
- 하단의 질문은 이미지의 **위치, 회전, 크기 변화에 대한 불변 특성**을 어떻게 효과적으로 추출할 수 있는지에 대한 것입니다.
- 일반적으로 **합성곱 신경망(CNN)** 은 이러한 불변성을 갖춘 특징을 추출하는 데 효과적입니다. CNN은 **작은 지역 단위(필터)를 사용해 이미지의 국소적인 특징을 학습**하며, 이는 **위치 변화나 일부 회전에 대해 상대적으로 강건한 특징**을 만들어줍니다.

이미지 처리에서 공간적 구조와 변형에 대한 유사성을 고려해야 하며, 이를 효율적으로 처리하기 위한 방법론이 필요합니다.

##### 질문: 계층적 특징을 어떻게 추출할 수 있을까?
- 하단의 질문은 이미지의 계층적 특징을 추출하는 방법에 대한 것으로, **합성곱 신경망(CNN)** 이 대표적인 해답이 됩니다.
- **CNN은 입력 이미지에서 작은 영역(필터)을 먼저 학습하며, 점점 더 넓은 영역의 특징을 추출함으로써 저수준에서 고수준으로 특징을 계층적으로 쌓아 나갑니다.**
- 이 과정을 통해 CNN은 선, 형태, 패턴 등의 특징을 효율적으로 학습하며, 이는 이미지 분류, 객체 인식 등의 다양한 이미지 처리 작업에서 매우 유용합니다.

이미지의 계층적 특성을 이해하고, 이를 효과적으로 추출하기 위해 계층적 접근이 필요합니다.

---
![[Pasted image 20241119140302.png]]
#### CNN이란?
- **CNN(Convolutional Neural Network)** 은 이미지와 같은 **격자 형태의 데이터(grid-like data)** 를 처리하도록 설계된 심층 신경망의 한 종류입니다.
- CNN은 이미지 처리에 자주 사용되며, 공간적 패턴을 잘 학습할 수 있는 특성을 가지고 있습니다. 이로 인해 컴퓨터 비전 분야에서 널리 활용됩니다.

#### CNN의 구성 요소
- CNN은 크게 두 부분으로 구성됩니다.
    ##### 1) 특징 추출(Feature extraction)
    - **합성곱 층(Convolution Layer)**: 이미지의 작은 영역에 필터(또는 커널)를 적용하여 **이미지의 국소적 특징을 추출**합니다. 필터는 이미지에서 중요한 패턴(모서리, 텍스처 등)을 인식하는 역할을 합니다.
    - **풀링 층(Pooling Layer)**: **특징 맵의 크기를 줄이기 위해 사용**됩니다. 가장 일반적인 풀링 방법은 최대 풀링(Max Pooling)으로, 특징 맵에서 특정 영역 내 최대 값을 선택해 정보를 압축하면서도 중요한 정보를 유지합니다.
    - 이 과정은 여러 번 반복되며, **이미지의 저수준부터 고수준까지 다양한 특징을 추출**하는 역할을 합니다.
    
    ##### 2) 결정(Decision making)
    - **완전 연결 층(Fully-Connected Layer, FC)**: CNN의 마지막 부분에서는 추출된 특징을 바탕으로 **분류**를 수행합니다.
    - 합성곱 및 풀링 층을 통과하여 학습된 특징을 평탄화(Flatten)한 후, 완전 연결 층에 전달하여 각 클래스에 대한 예측 값을 계산합니다.
    - 최종 출력은 클래스 확률을 나타내며, 예를 들어 "Computer", "Car", "Dog"와 같은 카테고리 중 하나로 분류됩니다.

#### 요약
- CNN은 **특징 추출**과 **결정**의 두 부분으로 이루어져 있으며, 합성곱과 풀링 층을 통해 이미지의 계층적 특징을 추출한 뒤, 완전 연결 층을 통해 최종적으로 분류 작업을 수행합니다.
- CNN의 구조는 **공간적 특징을 효율적으로 학습**할 수 있어, 이미지 분류, 객체 탐지 등 다양한 비전 작업에 효과적입니다.

---
![[Pasted image 20241119144103.png]]
#### MLP 모델
- MLP 모델은 입력 이미지가 **완전 연결층(Fully Connected Layer, FC)으로 직접 전달**됩니다.
- 이미지의 각 픽셀 값이 연결층을 통해 모델에 전달되고, **[[ReLU]]** 활성화 함수가 각 층에서 적용됩니다.
- MLP 모델은 모든 픽셀이 서로 연결된 구조로, 공간적 구조를 학습하지 못하고 각 픽셀을 독립적으로 처리합니다.
- 마지막에 **Softmax** 함수가 적용되어 각 클래스에 대한 확률을 출력하여 분류를 수행합니다.
- MLP는 이미지의 공간적 특징을 인식하기에 비효율적이며, 입력 크기에 따라 파라미터 수가 급격히 증가합니다.

#### 2. CNN 모델
- CNN 모델은 입력 이미지가 먼저 **합성곱 층(Convolution Layer)** 을 거칩니다. 합성곱 층은 필터를 사용하여 이미지의 국소적 특징을 추출합니다.
- 각 합성곱 층 이후에 **ReLU** 활성화 함수가 적용되고, **풀링 층(Pooling Layer)** 을 통해 특징 맵의 크기를 줄여 중요한 정보만 남깁니다.
- 이 과정을 여러 번 반복하여 저수준 특징부터 고수준 특징까지 계층적으로 학습하며, 이를 통해 이미지의 공간적 정보를 효과적으로 추출합니다.
- 최종적으로 추출된 특징은 **완전 연결층**에 전달되어 분류 작업이 수행됩니다. 마지막 Softmax 함수는 MLP와 동일하게 각 클래스에 대한 확률을 출력합니다.
- CNN은 **특징 추출 단계**와 **분류 단계**로 구성되어 있으며, 공간적 구조와 패턴을 효과적으로 학습할 수 있어 이미지 분류 작업에 더 적합합니다.

#### 요약
- **MLP 모델**은 모든 픽셀을 독립적으로 연결하는 방식으로, 이미지의 공간적 특징을 인식하지 못합니다.
- **CNN 모델**은 합성곱과 풀링 층을 통해 이미지의 공간적 정보를 계층적으로 학습하므로, 이미지의 특징을 효율적으로 추출하고 분류하는 데 매우 효과적입니다.

---
![[Pasted image 20241119144227.png]]
- 합성곱은 이미지 처리에서 흔히 사용되는 수학적 연산으로, **합성곱 필터(또는 커널, 마스크)**를 이미지에 적용하여 특정 특징을 강조하거나 추출합니다.
- 필터는 이미지의 작은 영역과 상호 작용하며, 특정 패턴(예: 모서리, 텍스처 등)을 감지하는 역할을 합니다.

#### 합성곱 과정
합성곱 연산은 다음과 같은 절차로 수행됩니다.
- **필터를 입력 행렬 위에 배치**합니다. 입력 행렬은 이미지 데이터이며, 필터는 특징을 추출하기 위한 작은 행렬입니다.
- **요소별 곱셈(Element-wise Multiplication)** 을 수행합니다. 필터와 입력 행렬의 각 요소를 위치에 맞게 곱합니다.
- **각 위치의 결과를 합산(Summing)** 하여 합성곱 결과를 얻습니다.
- 필터는 이미지 내에서 이동하며(stride), 각 위치에서의 연산 결과는 새로운 특징 맵을 형성하게 됩니다.

#### 예시
오른쪽 예시 그림에서,
- 필터를 각 위치에 겹쳐놓고, 요소별 곱셈과 합산을 통해 새로운 값을 생성합니다. 이 과정을 통해 입력 행렬에서 특정 패턴을 강조한 특징 맵이 생성됩니다.

![[Pasted image 20241119144528.png]]
##### 각 출력 행렬 셀의 의미
- 출력 행렬의 각 셀은 입력 행렬의 특정 영역에 필터를 적용한 결과입니다. **각 값은 해당 영역의 패턴을 필터가 얼마나 잘 감지했는지**를 나타냅니다.
- 이러한 출력 행렬은 이미지의 특정 특징을 강조하거나 감지하는 데 사용됩니다.

이 과정은 CNN에서 중요한 특징을 추출하고 학습하는 핵심 메커니즘으로, 필터가 학습을 통해 특정 패턴(예: 모서리, 질감 등)을 인식하도록 최적화됩니다.

---
![[Pasted image 20241119144723.png]]
패딩은 입력 데이터의 테두리에 추가 픽셀을 더하는 방법으로, 출력 크기를 조절하거나 가장자리에 있는 정보 손실을 방지하기 위해 사용됩니다.
#### 왜 패딩이 필요한가? (Why is Padding needed?)
- **합성곱 연산을 수행할 때 출력 크기가 점차 줄어듭니다.**
    - 예를 들어, 입력 행렬의 크기가 4×4이고, 3×3 필터를 사용하면, 출력 행렬은 2×2로 줄어듭니다.
    - 이러한 크기 감소는 여러 합성곱 층을 거치면서 더욱 작아질 수 있으며, 이는 입력 데이터의 정보가 손실될 위험이 있습니다.
- 패딩을 통해 출력 크기를 조절하고 정보 손실을 줄일 수 있습니다.

#### 패딩이란 무엇인가? (What is Padding?)
- **패딩(Padding)** 은 입력 데이터의 테두리에 추가적인 픽셀을 더하는 과정을 의미합니다.
    - 일반적으로 0으로 채우는 **제로 패딩(Zero Padding)** 이 많이 사용되며, 이는 입력 데이터의 크기를 인위적으로 늘려 출력 크기를 유지하도록 돕습니다.

#### 예시 설명
- 패딩이 없는 경우, 4×4 입력 행렬과 3×3 필터를 사용하면 출력이 2×2 크기로 줄어듭니다.
- 하지만 입력 데이터에 패딩을 추가하여 6×6 크기로 만든다면, 같은 필터를 사용해도 출력 크기가 더 커져 4×4 행렬을 얻을 수 있습니다.
- **패딩을 통해 입력 데이터의 가장자리 정보가 보존되며, 이는 모델이 이미지의 테두리 특징을 더 잘 학습할 수 있게 해줍니다.**

---
![[Pasted image 20241119144953.png]]
#### 스트라이드란?
- **스트라이드(Stride)** 는 합성곱 연산을 수행할 때 **필터가 가로 및 세로로 얼마나 이동하는지**를 나타내는 값입니다.
- 기본적으로 스트라이드가 1이면 필터가 한 칸씩 이동하며 입력 데이터의 모든 부분을 처리하게 됩니다. 스트라이드가 2 이상이면 필터가 두 칸씩 또는 그 이상 이동하여, 더 적은 연산을 수행하고 결과적으로 더 작은 출력이 생성됩니다.
- 스트라이드는 이미지의 조밀한 처리를 조절하여, 모델의 연산 복잡도를 줄이거나 출력의 크기를 조절하는 데 사용됩니다.

##### 예시: 4×4 입력, 3×3 필터, 스트라이드 1
- 이 예시에서는 4×4입력 행렬과 3×3필터, 그리고 **스트라이드가 1**로 설정되어 있습니다.
- 스트라이드가 1이므로 필터는 한 칸씩 오른쪽으로 이동하며, 각 위치에서 합성곱 연산을 수행합니다.
- 예를 들어, 첫 번째 위치에서 합성곱 연산을 수행하고 나면, (패딩이 없는 상태)필터가 오른쪽으로 한 칸 이동하여 다음 위치에서 연산을 수행합니다.
- 이 과정을 통해 2×2 크기의 출력 행렬이 생성됩니다.

![[Pasted image 20241119162059.png]]
- **입력 크기**: 4×4
- **필터 크기**: 2×2
- **패딩(Padding)**: 1 (입력 행렬의 테두리에 1픽셀 두께의 0을 추가)
- **스트라이드(Stride)**: 2 (필터가 두 칸씩 이동)

#### 패딩의 역할
- 패딩은 입력 데이터의 테두리에 추가 픽셀을 더해 **입력 크기를 확장**합니다.
- 여기서는 입력 행렬이 4×4에서 패딩을 추가하여 6×6 확장되었습니다.
- 패딩을 통해 가장자리에 위치한 특징들도 충분히 반영될 수 있게 하여, 출력에서 가장자리 정보가 보존될 수 있습니다.

#### 스트라이드의 역할
- 스트라이드가 2이므로 필터가 두 칸씩 이동하여 연산을 수행합니다.
- 이로 인해, 출력 크기는 작아지지만 연산이 더 간소화됩니다.
- 필터가 한 번 이동할 때마다 2×2영역에 대해 합성곱 연산을 수행하여 하나의 값을 출력합니다.

##### 예시 연산 과정
- 첫 번째 위치에서 합성곱 연산을 수행하고, 스트라이드에 따라 두 칸씩 이동하여 다음 위치에서 연산을 수행합니다.
- 필터가 이동하면서 입력 행렬에 겹치는 부분을 계산해 나가며, 최종적으로 출력이 생성됩니다.

##### 시각적 설명

- 오른쪽 그림에서는 패딩이 적용된 6×6 입력 행렬과 스트라이드가 2로 설정된 필터가 입력을 덮으며 연산하는 과정을 보여줍니다.
- 패딩이 적용되었기 때문에 가장자리 부분의 정보가 출력에 포함될 수 있으며, 스트라이드를 통해 연산 밀도를 조절하여 효율적으로 특징을 추출합니다.

---
![[Pasted image 20241119162748.png]]
RGB 이미지는 너비와 높이 외에도 색상 채널(R, G, B)을 포함하고 있어, 각 채널별로 별도의 처리가 필요합니다.
#### 3D 필터
- **3D 입력에는 3D 필터**가 필요합니다. 이 필터는 각 채널에 대해 별도로 적용되어야 합니다.
- 예시에서는 3×3×3 크기의 3D 필터가 사용됩니다.
- 필터의 채널 수는 입력 이미지의 채널 수와 동일해야 하며, 각 채널에 대응하는 부분이 입력의 해당 채널과 합성곱 연산을 수행합니다.

#### 패딩(Padding) 적용
- 입력 행렬에 패딩을 추가하여 경계 부분에서도 필터를 효과적으로 적용할 수 있도록 합니다. 패딩이 없으면 가장자리 픽셀이 충분히 처리되지 않아 경계 정보가 손실될 수 있습니다.

#### 합성곱 연산
1. 각 채널(R, G, B)에 대해 필터의 대응 부분을 적용하여 요소별 곱셈을 수행하고 합산합니다.
2. 각 채널에서 나온 결과를 합산하여 최종 출력 값을 생성합니다.
3. 이 결과로 새로운 2D 출력 맵이 만들어지며, 채널을 압축하여 단일 출력으로 생성됩니다.

##### 출력
- 최종 출력은 **M x N x 1** 형식의 단일 채널 맵이 됩니다.
- 예시에서는 모든 채널을 합성곱한 후 단일 출력 행렬을 얻습니다.

![[Pasted image 20241119165240.png]]
#### 다중 필터 사용
- **여러 개의 필터**가 사용될 수 있으며, 각 필터는 서로 다른 특징을 추출하도록 학습됩니다.
- 각 필터는 3D 형태로, 예를 들어 3×3×3크기로 구성됩니다. 이 크기는 입력 이미지의 채널 수와 일치해야 하며, 각 채널에 대해 별도로 합성곱 연산을 수행한 후 결과를 합산하여 단일 출력 채널을 만듭니다.

#### 출력 크기
- 다중 필터를 사용하면 **출력은 M×N×K 형식**이 됩니다.
    - M과 N은 출력의 너비와 높이이며, 패딩과 스트라이드 설정에 따라 결정됩니다.
    - K는 필터의 수를 나타내며, 각 필터는 서로 다른 특징을 추출하여 개별적인 출력 채널을 생성합니다.
- 여러 필터가 동시에 작동하여 다양한 특징 맵을 생성하고, CNN이 이미지의 다양한 패턴을 학습할 수 있도록 합니다.

##### 요약
- 다중 필터를 사용하여 하나의 3D 입력에서 다양한 특징을 추출할 수 있습니다.
- 각 필터는 특정 패턴을 학습하도록 최적화되며, 여러 필터가 함께 작동하여 이미지의 복잡한 특징을 효과적으로 분석합니다.
- 최종 출력은 M×N×K 크기의 특징 맵 세트가 되며, CNN 모델의 다음 층에서 더 높은 수준의 특징을 학습하는 기반이 됩니다.

---
![[Pasted image 20241119165538.png]]
풀링 층은 합성곱 층에서 얻어진 특징 맵을 축소하여 모델의 연산량을 줄이고, 특징을 압축하는 역할을 합니다.

#### 풀링이란 무엇인가? (What is Pooling?)
- 풀링은 **합성곱 층에서 얻은 출력 특징 맵을 부분 샘플링**하여 크기를 줄이는 과정입니다.
- 이를 통해 모델의 연산량이 줄어들며, 특징의 주요 정보는 유지하면서 불필요한 세부 정보를 제거할 수 있습니다.

#### 풀링 방식의 종류 (Types of Pooling Functions)
1. **맥스 풀링(Max Pooling)**
    - 각 필터 윈도우 내에서 **최대 값**을 선택하여 특징을 유지하는 방식입니다.
    - 예를 들어, 2×2 필터와 스트라이드가 2인 경우, 각 영역에서 가장 큰 값만 선택하여 새로운 특징 맵을 만듭니다.
    - 오른쪽 예시에서, 2×2크기의 윈도우가 각 영역에서 최대 값을 선택하여 축소된 맵을 생성합니다. 이 과정은 노이즈에 강하고 중요한 특징을 보존하는 데 유리합니다.
2. **평균 풀링(Average Pooling)**
    - 각 필터 윈도우 내의 모든 값의 **평균 값**을 계산하여 특징을 추출하는 방식입니다.
    - 이미지의 전반적인 흐름을 파악하는 데 적합하지만, 특정 패턴을 강조하는 데는 맥스 풀링보다 덜 효과적입니다.
3. **최소 풀링(Min Pooling)**
    - 각 필터 윈도우 내에서 **최소 값**을 선택하는 방식입니다.
    - 드물게 사용되며, 이미지에서 특정한 낮은 값을 강조할 때 사용될 수 있습니다.

#### 예시 설명
- 오른쪽 예시에서, 2×2 크기의 윈도우와 스트라이드가 2로 설정된 맥스 풀링 연산이 수행됩니다.
- 각 2×2 영역에서 최대 값이 선택되며, 이를 통해 입력 특징 맵이 더 작은 크기의 출력 특징 맵으로 압축됩니다.

#### 요약
- **풀링 층**은 특징 맵을 부분 샘플링하여 크기를 줄이고, 불필요한 정보를 제거하면서 중요한 정보를 유지합니다.
- CNN에서 주로 **맥스 풀링**이 사용되며, 이는 중요한 특징을 강조하면서 연산량을 줄여줍니다.

---
![[Pasted image 20241119165731.png]]
여러 합성곱 층을 사용함으로써 저수준에서 고수준까지 다양한 특징을 학습할 수 있습니다.

#### 다중 합성곱 층의 구성
- CNN은 입력 이미지에 대해 여러 개의 합성곱 층을 차례대로 적용하여 점차 복잡한 특징을 학습합니다.
- 각 합성곱 층은 서로 다른 필터를 사용하여 다양한 패턴을 추출하며, 층이 깊어질수록 점차 복잡한 형태나 패턴을 학습합니다.

##### 예시
1. **Conv1 (첫 번째 합성곱 층) - 저수준 특징(Low-Level Feature)**
    - 첫 번째 합성곱 층에서는 이미지의 기본적인 모양, 가장자리, 텍스처 등과 같은 저수준 특징이 학습됩니다.
    - 이 층에서는 간단한 선, 색상 패턴 등 이미지의 가장 기본적인 요소를 감지합니다.
2. **Conv2 (두 번째 합성곱 층) - 중간 수준 특징(Mid-Level Feature)**
    - 두 번째 층에서는 이전 층에서 추출한 기본 요소들을 결합하여 더 복잡한 패턴이나 형태를 학습합니다.
    - 예를 들어, 곡선이나 작은 물체 부분 등 중간 수준의 복합적인 형태가 학습될 수 있습니다.
3. **Conv3 (세 번째 합성곱 층) - 고수준 특징(High-Level Feature)** 
    - 세 번째 층에서는 객체나 특정 장면을 인식할 수 있는 고수준 특징이 학습됩니다.
    - 이 층에서는 자동차의 전체적인 형태나 특정 패턴과 같이 구체적인 객체 인식이 가능해집니다.

#### 계층적 특징 추출
- CNN에서 여러 합성곱 층을 쌓는 것은 **계층적 특징 추출**을 가능하게 합니다. 각 층이 서로 다른 수준의 특징을 학습함으로써, CNN은 이미지의 다양한 측면을 포착할 수 있습니다.
- 마지막에는 **Classifier** 가 연결되어, 학습한 특징을 기반으로 이미지의 특정 클래스를 예측합니다.

---
![[Pasted image 20241119170009.png]]
### CNN 모델의 구조
1. **특징 추출 단계 (Feature Extraction)**
    - **합성곱 층(Conv layer)**: 입력 이미지에서 저수준 특징을 추출합니다. 각 합성곱 층에서는 여러 필터를 사용하여 가장자리, 텍스처, 패턴 등의 저수준 특징을 학습합니다.
    - **ReLU 활성화 함수**: 각 합성곱 층의 결과에 비선형성을 추가하여 모델이 복잡한 특징을 학습할 수 있도록 합니다.
    - **풀링 층(Pooling layer)**: 풀링을 통해 특징 맵의 크기를 줄여 모델의 계산 비용을 감소시키고, 위치 불변성을 높입니다. Max Pooling이 일반적으로 사용됩니다.
    - 이러한 합성곱과 풀링 층이 여러 번 반복되면서, 저수준부터 고수준의 특징으로 점차 복잡한 특징을 학습해 나갑니다.
2. **특징 수준별 학습**
    - CNN은 층이 깊어질수록 **저수준 특징(Low-Level Features)** 에서 **중간 수준 특징(Mid-Level Features)** , 그리고 **고수준 특징(High-Level Features)** 로 특징을 점차적으로 학습합니다.
    - 첫 번째 합성곱 층에서는 선과 같은 기본 패턴이, 중간 층에서는 더 복잡한 모양이, 마지막 층에서는 객체의 형태가 학습됩니다.
3. **결정 단계 (Decision Making)**
    - **완전 연결 층(Fully Connected Layer, FC layer)**: 특징 추출 단계에서 얻어진 고수준 특징을 기반으로 분류 작업을 수행합니다.
    - **Softmax 층**: 마지막 단계에서 각 클래스에 대한 확률을 계산하여 이미지가 특정 클래스에 속할 확률을 예측합니다.

CNN은 입력 이미지에서 저수준부터 고수준까지 다양한 특징을 추출하여 계층적으로 학습합니다.
최종적으로 완전 연결 층을 통해 학습된 특징을 기반으로 이미지가 속할 클래스를 예측하게 됩니다.

---
![[Pasted image 20241119170357.png]]
완전 연결층은 CNN의 합성곱과 풀링 단계에서 추출된 특징을 기반으로 최종 분류를 수행합니다.

#### 완전 연결층의 역할
- **완전 연결층(Fully-Connected Layer, MN)** 은 다차원 특징 벡터를 입력으로 받아서 새로운 차원의 벡터로 변환합니다.
    - 여기서 M×N은 각 층 사이의 가중치 파라미터 수를 나타내며, 입력 차원 M과 출력 차원 N에 따라 결정됩니다.
    - 이 층은 CNN이 이미지에서 추출한 특징들을 조합하여 클래스에 대한 정보를 강화하거나 조합하는 역할을 합니다.
- CNN의 마지막 단계에서 완전 연결층은 추출된 특징들을 기반으로 최종 분류 작업을 수행하며, 모델의 학습을 통해 각 클래스에 대한 신뢰도를 계산할 수 있습니다.

#### 특징 표현을 분류에 적합한 형태로 변환
- 합성곱 및 풀링 층을 거치면서 추출된 **고수준 특징(high-level features)** 은 완전 연결층을 통해 클래스 간 구별 가능한 표현으로 변환됩니다.
- 이를 통해 모델은 특정 클래스에 속할 확률을 계산하여 예측을 수행할 수 있습니다.

#### 구조 설명
- **CNN의 전체 흐름에서는 합성곱과 풀링을 통해 특징을 추출한 후, 완전 연결층으로 연결**됩니다.
- 완전 연결층에서는 모든 노드가 서로 연결되어 있으며, 입력 특징 벡터를 기반으로 각 출력 노드(클래스)에 대한 예측 값을 계산합니다.
- 최종 출력 벡터는 클래스의 확률 분포를 나타내며, 소프트맥스(Softmax) 함수 등을 통해 클래스별 확률을 구할 수 있습니다.

---
![[Pasted image 20241119170614.png]]
소프트맥스 함수는 모델의 출력 값을 확률 분포로 변환하여, 각 클래스에 속할 확률을 계산하는 데 사용됩니다.

#### 소프트맥스 함수란?
- **소프트맥스 함수**는 모델의 **원시 출력 값(raw output values)** 을 받아 각 클래스에 대한 **확률 값**으로 변환합니다.
- 이 확률 값들은 0에서 1 사이에 위치하며, 모든 클래스에 대한 확률의 합은 1이 됩니다.
- 소프트맥스 함수는 출력 값을 해석 가능하게 만들어주며, 분류 문제에서 각 클래스에 속할 확률을 제공하기 때문에 분류 결과를 결정하는 데 유용합니다.

z_i​는 입력 벡터 z의 i번째 요소
n은 입력 벡터 z의 전체 요소 수, 즉 클래스의 총 개수를 나타냅니다.
각 z_i에 대해 지수 함수 exp(z_i)를 적용하고, 그 값을 모든 출력 요소의 지수 함수 값의 합으로 나눔으로써 확률을 계산합니다.

##### 소프트맥스 함수 적용 예시
- 예를 들어, 모델의 최종 출력이 [2.0, −1.2, …, 0.8]과 같은 벡터라면, 이 벡터에 소프트맥스 함수를 적용하여 각 클래스에 대한 확률을 계산합니다.
- 예시 결과로 오른쪽에 나온 확률 벡터 [0.12, 0.02, …, 0.65]는 각 클래스에 속할 확률을 나타내며, 가장 높은 확률인 0.65를 가진 클래스가 최종 예측으로 선택됩니다.

---
![[Pasted image 20241119170941.png]]
#### 교차 엔트로피 손실(Cross Entropy Loss)이란?
- 교차 엔트로피 손실은 **모델의 예측 확률 분포와 실제 클래스 레이블의 차이**를 측정하는 함수입니다.
- 이 손실 함수는 **예측된 확률 값이 실제 레이블과 얼마나 가까운지**를 평가하는 데 사용됩니다.
- 값이 작을수록 모델의 예측이 실제 레이블과 유사하며, 값이 클수록 모델이 틀린 예측을 하고 있음을 의미합니다.

![[Pasted image 20241119171149.png]]

##### 예시
- 오른쪽 예시에서는 실제 레이블 y가 7번 클래스이며, 모델의 예측 확률 y^​에서 7번 클래스에 대한 확률이 0.65로 예측되었습니다.
- 교차 엔트로피 손실 함수는 예측된 0.65와 실제 값 1 사이의 차이를 기반으로 손실을 계산하며, 이 값을 통해 모델이 얼마나 정확히 예측했는지 평가합니다.

---
![[Pasted image 20241119171225.png]]
데이터 증강은 원본 이미지를 다양한 방식으로 변형하여 데이터의 다양성을 높이고, 모델의 일반화 성능을 향상시키기 위한 기법입니다.

#### 데이터 증강이란?
- 데이터 증강은 CNN 모델의 성능을 향상시키기 위해 **원본 데이터를 변형하여 새로운 학습 데이터를 생성**하는 과정입니다.
- 모델이 다양한 상황에 대응할 수 있도록 이미지의 위치, 크기, 색상, 회전 등을 변형한 데이터를 생성하여 학습시킵니다.
- 원본 이미지의 라벨은 그대로 유지되지만, 변형된 다양한 이미지를 모델에 제공하여 모델이 위치, 색상, 회전, 크기 변화에 강인한 특징을 학습하게 합니다.

#### 데이터 증강의 예시
1. **회전(Rotation)**: 이미지를 회전하여 다른 각도에서 인식하도록 학습합니다.
2. **크기 조절 및 자르기(Crop and Resize)**: 이미지의 일부를 잘라내거나 크기를 조절하여 학습합니다.
3. **색상 왜곡(Color Distortion)**: 색상의 강도를 변화시키거나 흑백으로 변환하여 색상 변화에 대해 모델이 견고해지도록 합니다.
4. **좌우 반전(Flip)**: 이미지를 좌우로 뒤집어 좌우 방향에 대한 변화를 학습하게 합니다.
5. **잘라내기(Cutout)**: 이미지의 일부를 제거하여 나머지 부분만으로도 학습할 수 있도록 만듭니다.
6. **노이즈 추가(Gaussian Noise)**: 노이즈를 추가하여 이미지의 노이즈에 대한 강건성을 높입니다.
7. **블러링(Blurring)**: 가우시안 블러 등을 사용하여 흐릿하게 만들어, 흐릿한 이미지에서도 인식할 수 있도록 학습합니다.
8. **필터링(Sobel Filtering)**: 엣지 감지를 위한 필터를 적용하여 윤곽선을 강조한 데이터를 생성합니다.

#### 데이터 증강의 효과
- 데이터 증강은 모델이 다양한 형태의 데이터에 대해 잘 대응할 수 있게 만들어 **위치, 색상, 회전, 크기 변화에 대해 강인한 모델**을 만듭니다.
- 이를 통해 모델이 한정된 원본 데이터셋으로도 더 많은 변형 상황을 학습하게 되어 **일반화 성능**이 향상됩니다.

